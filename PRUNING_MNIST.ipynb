{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels)= mnist.load_data()"
      ],
      "metadata": {
        "id": "lWJR9mC3f5Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d9566f-bd6c-4b15-c5b1-cf8504a58f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK8q-aXv_Lkq",
        "outputId": "b4805ead-b487-44b7-916b-8243cc436482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_dim=28*28),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Ok3doRRqaOvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images= train_images.reshape((60000, 28*28))\n",
        "test_images= test_images.reshape((10000, 28*28))\n",
        "\n",
        "train_images= train_images.astype('float32')/255\n",
        "test_images= test_images.astype('float32')/255\n"
      ],
      "metadata": {
        "id": "PiAT24gxGziX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCyiA-R4FCf9",
        "outputId": "aa60f301-cbab-4a0c-fff2-81d744345823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('drive/MyDrive/weights4/')"
      ],
      "metadata": {
        "id": "txhIoev7wPdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights=model.get_weights()"
      ],
      "metadata": {
        "id": "Wjc015nYwKi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights= model.get_weights()\n",
        "\n",
        "# Input to Hidden Weights\n",
        "print(\"Input to Hidden Weights\")\n",
        "print(\"───────────────────────\")\n",
        "print(initial_weights[0])\n",
        "\n",
        "# Bias vector for Hidden Neurons\n",
        "print(\"\\nBias vector for Hidden Neurons\")\n",
        "print(\"────────────────────────────\")\n",
        "print(initial_weights[1])\n",
        "\n",
        "# Hidden to Output Weights\n",
        "print(\"\\nHidden to Output Weights\")\n",
        "print(\"────────────────────────\")\n",
        "print(initial_weights[2])\n",
        "\n",
        "# Bias for output Neuron\n",
        "print(\"\\nBias for Output Neuron\")\n",
        "print(\"───────────────────────\")\n",
        "print(initial_weights[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGG1nXEREJgn",
        "outputId": "ebdac542-a0f9-4da6-e517-8da39490de70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to Hidden Weights\n",
            "───────────────────────\n",
            "[[-0.01049487 -0.04082505 -0.05311067 ... -0.02461446 -0.01769529\n",
            "  -0.03066614]\n",
            " [-0.04644672 -0.01665151  0.06456935 ... -0.04332058 -0.02204521\n",
            "  -0.00645933]\n",
            " [-0.06531794 -0.0657871  -0.06302863 ... -0.04905161 -0.01629963\n",
            "   0.06038645]\n",
            " ...\n",
            " [-0.02509523 -0.01623917 -0.00222937 ... -0.04106769  0.06380601\n",
            "   0.01144135]\n",
            " [-0.06308652  0.0148191  -0.05744663 ... -0.05516207 -0.01310738\n",
            "   0.0342321 ]\n",
            " [ 0.02535346 -0.00919089  0.00314657 ...  0.05279838  0.02427322\n",
            "   0.06737055]]\n",
            "\n",
            "Bias vector for Hidden Neurons\n",
            "────────────────────────────\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Hidden to Output Weights\n",
            "────────────────────────\n",
            "[[ 0.07450896  0.09845426 -0.10092569 ...  0.04148253  0.0396964\n",
            "   0.05629098]\n",
            " [-0.07680964 -0.01851919  0.06118525 ...  0.02565239 -0.0561589\n",
            "   0.09805464]\n",
            " [ 0.07813083 -0.10279784 -0.05529987 ...  0.10429298 -0.06938747\n",
            "   0.04443207]\n",
            " ...\n",
            " [-0.09116854 -0.10482277  0.03243583 ... -0.08824759 -0.09049135\n",
            "   0.05129079]\n",
            " [ 0.08977548 -0.09347842 -0.05627104 ... -0.09525674  0.03759869\n",
            "   0.03919374]\n",
            " [-0.06657781  0.07746141 -0.06830508 ... -0.0072538   0.08355699\n",
            "  -0.01005159]]\n",
            "\n",
            "Bias for Output Neuron\n",
            "───────────────────────\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size= 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUpAvSI29zcB",
        "outputId": "1659003b-dcc8-4bf0-c565-4ae9afb6a444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "600/600 [==============================] - 8s 13ms/step - loss: 0.2470 - accuracy: 0.9300\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 0.0981 - accuracy: 0.9710\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0650 - accuracy: 0.9801\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.0469 - accuracy: 0.9855\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0353 - accuracy: 0.9892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x784d444074c0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux4gI2OVVCnw",
        "outputId": "ae5636b8-2eff-4b48-a1b0-3d4a38be7d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.9799000024795532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "XglO6WFhAMSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9c4912-28d0-4028-d079-c7340d4de26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/241.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/241.2 kB\u001b[0m \u001b[31m815.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/241.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "D2TIu5iFGC9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "F6FpqMTp-xcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "batch_size = 100\n",
        "epochs= 5\n",
        "validation_split = 0.1\n",
        "\n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "pruning_params = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                             final_sparsity=0.80,\n",
        "                                                             begin_step=0,\n",
        "                                                             end_step=end_step)\n",
        "}\n",
        "\n",
        "model2 = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_dim=28*28),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model2.load_weights('drive/MyDrive/weights4/')\n"
      ],
      "metadata": {
        "id": "sXmG39YqGRXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146f4d8e-d982-4c55-d405-1c64bc2eda28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x784d46fedd50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model2_weights= model2.get_weights()\n",
        "# Input to Hidden Weights\n",
        "print(\"Input to Hidden Weights\")\n",
        "print(\"───────────────────────\")\n",
        "print(model2_weights[0])\n",
        "\n",
        "# Bias vector for Hidden Neurons\n",
        "print(\"\\nBias vector for Hidden Neurons\")\n",
        "print(\"────────────────────────────\")\n",
        "print(model2_weights[1])\n",
        "\n",
        "# Hidden to Output Weights\n",
        "print(\"\\nHidden to Output Weights\")\n",
        "print(\"────────────────────────\")\n",
        "print(model2_weights[2])\n",
        "\n",
        "# Bias for output Neuron\n",
        "print(\"\\nBias for Output Neuron\")\n",
        "print(\"───────────────────────\")\n",
        "print(model2_weights[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9C9eDf3GC2Y",
        "outputId": "c2200ce4-0760-4c35-d584-dd857f637f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to Hidden Weights\n",
            "───────────────────────\n",
            "[[-0.         -0.         -0.         ... -0.         -0.\n",
            "  -0.        ]\n",
            " [-0.         -0.          0.06456935 ... -0.         -0.\n",
            "  -0.        ]\n",
            " [-0.06531794 -0.0657871  -0.06302863 ... -0.         -0.\n",
            "   0.06038645]\n",
            " ...\n",
            " [-0.         -0.         -0.         ... -0.          0.06380601\n",
            "   0.        ]\n",
            " [-0.06308652  0.         -0.05744663 ... -0.         -0.\n",
            "   0.        ]\n",
            " [ 0.         -0.          0.         ...  0.          0.\n",
            "   0.06737055]]\n",
            "\n",
            "Bias vector for Hidden Neurons\n",
            "────────────────────────────\n",
            "[ 0.00923608  0.06360403  0.06013612 -0.00159987  0.00090803 -0.07706109\n",
            " -0.12722225 -0.02115901 -0.0838457   0.00719486  0.07902507  0.01987891\n",
            " -0.02188208  0.04181153  0.06763232  0.06041931  0.05791906  0.01864749\n",
            " -0.00813717  0.10731354 -0.00165496  0.0489861   0.00894555  0.06649777\n",
            "  0.0300867   0.05135164 -0.00750342 -0.08424181  0.03854689 -0.02741542\n",
            "  0.10848355  0.01651354  0.02925604  0.03225194  0.01321194  0.00486653\n",
            " -0.02648169  0.09596621 -0.03631946  0.0189401   0.06962129  0.11965889\n",
            " -0.0437014  -0.00734536 -0.01264911  0.04460785  0.03543996 -0.01120963\n",
            " -0.02360379  0.03619245 -0.05984022 -0.07132641 -0.01044146  0.0082316\n",
            "  0.02270957  0.00320903 -0.03066325 -0.05073321  0.00745599  0.00302888\n",
            " -0.03312027 -0.01966019  0.063102    0.10509375 -0.04097236  0.11149932\n",
            "  0.00157925 -0.03758806  0.00149708 -0.06588541  0.01314653  0.0575012\n",
            "  0.04665302  0.02346429 -0.02549097  0.02890633  0.01377976  0.06989835\n",
            "  0.03511499 -0.00295113  0.00037757  0.00018727  0.02827058  0.08300954\n",
            "  0.06839307  0.00759823 -0.02798272 -0.03932795  0.03467533 -0.01149802\n",
            "  0.03584066  0.0603829  -0.0337625   0.01743139  0.04724061  0.02594061\n",
            " -0.06835175  0.04615482  0.02334904 -0.03539784 -0.00889309 -0.05859107\n",
            " -0.06227135 -0.00683175  0.01441165 -0.0096837   0.02862841  0.02221565\n",
            " -0.04926638 -0.032562    0.04223718  0.04052019  0.00598931  0.06528821\n",
            " -0.03724706  0.06948172 -0.04344984  0.00051194 -0.00872816  0.0706379\n",
            "  0.00632228 -0.00366686 -0.01478322  0.07232519 -0.0803567   0.08816529\n",
            "  0.0680468   0.03656542 -0.13669878 -0.0115524  -0.01260065 -0.00540353\n",
            " -0.02480314  0.02562262  0.01878651 -0.00435168 -0.02008405  0.01900101\n",
            " -0.00641023  0.00983201  0.02389668 -0.02672647 -0.00126868 -0.03948824\n",
            "  0.03476845 -0.02371578  0.06168365 -0.01660694  0.02698557 -0.01017092\n",
            "  0.06290391  0.03556103  0.04152856  0.10701206 -0.04690943  0.07796387\n",
            " -0.00892473  0.00714141 -0.03135205 -0.02119644 -0.03987874  0.00904969\n",
            "  0.03740353  0.03870752  0.01846357  0.03837575 -0.02816023  0.09712169\n",
            " -0.0037195  -0.04300613 -0.0154162  -0.05625835  0.02914844  0.0171073\n",
            " -0.03156416 -0.0695642  -0.03626753 -0.01635629 -0.08005439 -0.08597356\n",
            " -0.04216662 -0.04815261  0.0394957  -0.01404974 -0.00364608  0.09160304\n",
            "  0.05165796  0.04462574 -0.07384126  0.04261011  0.07791669  0.06598622\n",
            "  0.1057889   0.05125806 -0.01614742 -0.00615996  0.08294511  0.01251815\n",
            " -0.03714981  0.01085306 -0.01328322 -0.0504429  -0.02157401  0.00952708\n",
            "  0.02950718  0.091218   -0.08202204  0.08427433  0.06619941 -0.0603001\n",
            " -0.02724924  0.0586716   0.03446574 -0.01435415 -0.02072423 -0.00294233\n",
            " -0.03397958 -0.01532629 -0.01169266  0.07165437  0.0386686  -0.04917542\n",
            "  0.02584689  0.06082812  0.05213424 -0.00038519 -0.06418698  0.04675699\n",
            "  0.04878818  0.08522116 -0.00655381  0.0490751  -0.01402193  0.02811201\n",
            " -0.0746011   0.08514383  0.02657601  0.01877743  0.11743415  0.02166902\n",
            "  0.15152155 -0.01699232  0.07183276  0.05115941 -0.04706223 -0.00850397\n",
            "  0.03458915  0.06377429  0.09164136 -0.05010843 -0.05573216  0.05007796\n",
            "  0.03321009 -0.03164304 -0.02811497  0.02656393 -0.07150734 -0.03867992\n",
            " -0.01189515  0.00767912  0.0753234   0.04527732  0.04097278  0.06148712\n",
            "  0.04289699  0.02258096  0.0675118  -0.02726303 -0.01709712 -0.00351795\n",
            "  0.04041767  0.01850721  0.06901029 -0.05679356 -0.04344379 -0.00711314\n",
            " -0.02004676  0.04653659 -0.03777293 -0.04421678  0.00913509 -0.0657548\n",
            "  0.01407253  0.05089712 -0.10406277 -0.01928236 -0.1355432   0.02877995\n",
            " -0.05278252  0.02016695  0.00261306 -0.00922521  0.00988076 -0.03517292\n",
            " -0.07257485 -0.02775101  0.06142663 -0.03887116 -0.04792688 -0.05933068\n",
            " -0.03212671 -0.00718403  0.00475253  0.02581315  0.00677497  0.03284954\n",
            " -0.00937904 -0.00299308  0.02524505  0.02257301  0.01669064  0.01550477\n",
            " -0.03843421  0.0192384   0.02195187 -0.05956763 -0.0014735  -0.02582246\n",
            "  0.01706225 -0.00437493  0.00892576  0.02099262  0.01382517  0.0271719\n",
            "  0.07364381 -0.01253449 -0.08373099  0.02731678 -0.03981555  0.00462771\n",
            " -0.02051537 -0.01233808  0.09598774  0.0414351   0.1423061  -0.08239342\n",
            "  0.07511931 -0.00504595 -0.04541733  0.06070369  0.05893687  0.03988843\n",
            "  0.01786886  0.03648331  0.03753839 -0.01008363  0.01741371 -0.04170849\n",
            "  0.0550492   0.01363357  0.0060408   0.06800457 -0.02672449  0.00732579\n",
            "  0.0939324   0.07014644 -0.00174568 -0.00384836 -0.03249849 -0.01289398\n",
            "  0.04767874  0.04693499 -0.07564781  0.02551229  0.02185111  0.0340694\n",
            "  0.04300012  0.00457303 -0.00439752 -0.07436907 -0.03044019 -0.09536605\n",
            "  0.05848373  0.01773322  0.03324027  0.01988043  0.01706287 -0.02197149\n",
            "  0.02939152  0.03639091 -0.00571249  0.08664902 -0.0386609   0.01423961\n",
            " -0.0124596   0.07426126 -0.02315525  0.09704097  0.04431284 -0.01560661\n",
            "  0.00656012  0.12334087 -0.03568402  0.02985649  0.02587489  0.02904386\n",
            " -0.00973366  0.02386793  0.00748295  0.07407155  0.01330972  0.04763379\n",
            "  0.05366801  0.08457668  0.03928425 -0.05181443  0.04788182  0.07709248\n",
            " -0.01172379  0.02970502 -0.00043991 -0.00620989  0.00878494 -0.00621177\n",
            "  0.00023147 -0.01241718  0.10861629 -0.01269052  0.03372663 -0.03284307\n",
            "  0.0238579  -0.00283238 -0.03128052 -0.03286495  0.02727329  0.05804717\n",
            " -0.02133219 -0.05236638  0.04747227  0.00185013  0.04524364 -0.04232267\n",
            "  0.02442057  0.0157615   0.08995111  0.05771054  0.02861718 -0.03559668\n",
            "  0.00678403  0.01808359  0.03709375  0.02800547  0.00728697  0.05135056\n",
            " -0.05175245  0.09771194 -0.00923032  0.02404552  0.0605599   0.03087374\n",
            " -0.00766468  0.05170628  0.05457668  0.03458627 -0.0090338   0.11389384\n",
            "  0.05708011  0.00235167  0.01571353 -0.03069654 -0.09382347 -0.01755263\n",
            "  0.01155968  0.01157283 -0.05555885 -0.01143215  0.02330771  0.03230364\n",
            "  0.16445163  0.05730947 -0.03239491  0.05842143 -0.0456834   0.05681127\n",
            " -0.08505525 -0.02843384 -0.00158534 -0.0193859  -0.06144567  0.04654796\n",
            " -0.03644407 -0.03863682  0.00831568 -0.00839029 -0.02604878 -0.03273244\n",
            "  0.07036489 -0.00474835 -0.0539573   0.02857297 -0.02779709  0.00204781\n",
            "  0.01316103  0.01304111  0.10104925 -0.05618409  0.04676189  0.02870407\n",
            "  0.02328723  0.02337837  0.00662436  0.07478151  0.02705667  0.06591668\n",
            " -0.00161757  0.05897271 -0.06413344 -0.03750644 -0.06564444  0.03784489\n",
            "  0.06948254 -0.0795084 ]\n",
            "\n",
            "Hidden to Output Weights\n",
            "────────────────────────\n",
            "[[-0.         -0.         -0.28774634 ... -0.          0.\n",
            "   0.        ]\n",
            " [-0.27510467 -0.          0.         ... -0.          0.\n",
            "   0.        ]\n",
            " [-0.         -0.3585984   0.         ... -0.          0.\n",
            "   0.        ]\n",
            " ...\n",
            " [-0.3488775   0.          0.         ... -0.25522473 -0.23641942\n",
            "  -0.        ]\n",
            " [-0.         -0.25991586  0.         ... -0.          0.\n",
            "   0.        ]\n",
            " [-0.          0.          0.         ...  0.         -0.\n",
            "   0.        ]]\n",
            "\n",
            "Bias for Output Neuron\n",
            "───────────────────────\n",
            "[-0.10533774 -0.0584163  -0.02285371 -0.05974628  0.01496729  0.03890281\n",
            " -0.01635682 -0.0391984   0.10775994 -0.03754989]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model2, **pruning_params)\n",
        "\n",
        "model_for_pruning.compile(optimizer='rmsprop',\n",
        "                          loss='sparse_categorical_crossentropy',\n",
        "                          metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "V6mH8pK09x84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_pruning.summary()"
      ],
      "metadata": {
        "id": "PQ3eKUas-rRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3a0a95-84e9-4864-8937-e67002935a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_dense_  (None, 512)               803330    \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                10252     \n",
            " 3 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813582 (3.10 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 406532 (1.55 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "logdir = tempfile.mkdtemp()\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]"
      ],
      "metadata": {
        "id": "wb-tIP5rEOdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_pruning.fit(train_images, train_labels, epochs=5, batch_size= 100, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "9I9wlQjTGgjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a9a947-e5f3-4b38-e028-d3afe68d58bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "600/600 [==============================] - 9s 12ms/step - loss: 0.2669 - accuracy: 0.9239\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1245 - accuracy: 0.9647\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 6s 10ms/step - loss: 0.0894 - accuracy: 0.9753\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 9s 14ms/step - loss: 0.0709 - accuracy: 0.9801\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 6s 10ms/step - loss: 0.0584 - accuracy: 0.9835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x784d46dc6f20>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Pruned test accuracy:  ', model_for_pruning_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTpygxAEHW7W",
        "outputId": "3e8b84b2-5b87-4693-c2f6-1eeb5ff723a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.9799000024795532\n",
            "Pruned test accuracy:   0.9775999784469604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_weights= model_for_pruning.get_weights()"
      ],
      "metadata": {
        "id": "8jyQ5nGv4eQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weights for the original model:\")\n",
        "for i, weight in enumerate(initial_weights):\n",
        "    print(f\"Weight {i + 1} - Shape: {weight.shape}\")\n",
        "    print(weight)\n",
        "\n",
        "# Iterate through and print all weights for the pruned model\n",
        "print(\"\\nWeights for the pruned model:\")\n",
        "for i, weight in enumerate(model2_weights):\n",
        "    print(f\"Weight {i + 1} - Shape: {weight.shape}\")\n",
        "    print(weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb-oBzE-31TC",
        "outputId": "21f62d54-7fa0-4a59-eacb-466c46da6783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights for the original model:\n",
            "Weight 1 - Shape: (784, 512)\n",
            "[[-0.01049487 -0.04082505 -0.05311067 ... -0.02461446 -0.01769529\n",
            "  -0.03066614]\n",
            " [-0.04644672 -0.01665151  0.06456935 ... -0.04332058 -0.02204521\n",
            "  -0.00645933]\n",
            " [-0.06531794 -0.0657871  -0.06302863 ... -0.04905161 -0.01629963\n",
            "   0.06038645]\n",
            " ...\n",
            " [-0.02509523 -0.01623917 -0.00222937 ... -0.04106769  0.06380601\n",
            "   0.01144135]\n",
            " [-0.06308652  0.0148191  -0.05744663 ... -0.05516207 -0.01310738\n",
            "   0.0342321 ]\n",
            " [ 0.02535346 -0.00919089  0.00314657 ...  0.05279838  0.02427322\n",
            "   0.06737055]]\n",
            "Weight 2 - Shape: (512,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Weight 3 - Shape: (512, 10)\n",
            "[[ 0.07450896  0.09845426 -0.10092569 ...  0.04148253  0.0396964\n",
            "   0.05629098]\n",
            " [-0.07680964 -0.01851919  0.06118525 ...  0.02565239 -0.0561589\n",
            "   0.09805464]\n",
            " [ 0.07813083 -0.10279784 -0.05529987 ...  0.10429298 -0.06938747\n",
            "   0.04443207]\n",
            " ...\n",
            " [-0.09116854 -0.10482277  0.03243583 ... -0.08824759 -0.09049135\n",
            "   0.05129079]\n",
            " [ 0.08977548 -0.09347842 -0.05627104 ... -0.09525674  0.03759869\n",
            "   0.03919374]\n",
            " [-0.06657781  0.07746141 -0.06830508 ... -0.0072538   0.08355699\n",
            "  -0.01005159]]\n",
            "Weight 4 - Shape: (10,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Weights for the pruned model:\n",
            "Weight 1 - Shape: (784, 512)\n",
            "[[-0.         -0.         -0.         ... -0.         -0.\n",
            "  -0.        ]\n",
            " [-0.         -0.          0.06456935 ... -0.         -0.\n",
            "  -0.        ]\n",
            " [-0.06531794 -0.0657871  -0.06302863 ... -0.         -0.\n",
            "   0.06038645]\n",
            " ...\n",
            " [-0.         -0.         -0.         ... -0.          0.06380601\n",
            "   0.        ]\n",
            " [-0.06308652  0.         -0.05744663 ... -0.         -0.\n",
            "   0.        ]\n",
            " [ 0.         -0.          0.         ...  0.          0.\n",
            "   0.06737055]]\n",
            "Weight 2 - Shape: (512,)\n",
            "[ 0.00923608  0.06360403  0.06013612 -0.00159987  0.00090803 -0.07706109\n",
            " -0.12722225 -0.02115901 -0.0838457   0.00719486  0.07902507  0.01987891\n",
            " -0.02188208  0.04181153  0.06763232  0.06041931  0.05791906  0.01864749\n",
            " -0.00813717  0.10731354 -0.00165496  0.0489861   0.00894555  0.06649777\n",
            "  0.0300867   0.05135164 -0.00750342 -0.08424181  0.03854689 -0.02741542\n",
            "  0.10848355  0.01651354  0.02925604  0.03225194  0.01321194  0.00486653\n",
            " -0.02648169  0.09596621 -0.03631946  0.0189401   0.06962129  0.11965889\n",
            " -0.0437014  -0.00734536 -0.01264911  0.04460785  0.03543996 -0.01120963\n",
            " -0.02360379  0.03619245 -0.05984022 -0.07132641 -0.01044146  0.0082316\n",
            "  0.02270957  0.00320903 -0.03066325 -0.05073321  0.00745599  0.00302888\n",
            " -0.03312027 -0.01966019  0.063102    0.10509375 -0.04097236  0.11149932\n",
            "  0.00157925 -0.03758806  0.00149708 -0.06588541  0.01314653  0.0575012\n",
            "  0.04665302  0.02346429 -0.02549097  0.02890633  0.01377976  0.06989835\n",
            "  0.03511499 -0.00295113  0.00037757  0.00018727  0.02827058  0.08300954\n",
            "  0.06839307  0.00759823 -0.02798272 -0.03932795  0.03467533 -0.01149802\n",
            "  0.03584066  0.0603829  -0.0337625   0.01743139  0.04724061  0.02594061\n",
            " -0.06835175  0.04615482  0.02334904 -0.03539784 -0.00889309 -0.05859107\n",
            " -0.06227135 -0.00683175  0.01441165 -0.0096837   0.02862841  0.02221565\n",
            " -0.04926638 -0.032562    0.04223718  0.04052019  0.00598931  0.06528821\n",
            " -0.03724706  0.06948172 -0.04344984  0.00051194 -0.00872816  0.0706379\n",
            "  0.00632228 -0.00366686 -0.01478322  0.07232519 -0.0803567   0.08816529\n",
            "  0.0680468   0.03656542 -0.13669878 -0.0115524  -0.01260065 -0.00540353\n",
            " -0.02480314  0.02562262  0.01878651 -0.00435168 -0.02008405  0.01900101\n",
            " -0.00641023  0.00983201  0.02389668 -0.02672647 -0.00126868 -0.03948824\n",
            "  0.03476845 -0.02371578  0.06168365 -0.01660694  0.02698557 -0.01017092\n",
            "  0.06290391  0.03556103  0.04152856  0.10701206 -0.04690943  0.07796387\n",
            " -0.00892473  0.00714141 -0.03135205 -0.02119644 -0.03987874  0.00904969\n",
            "  0.03740353  0.03870752  0.01846357  0.03837575 -0.02816023  0.09712169\n",
            " -0.0037195  -0.04300613 -0.0154162  -0.05625835  0.02914844  0.0171073\n",
            " -0.03156416 -0.0695642  -0.03626753 -0.01635629 -0.08005439 -0.08597356\n",
            " -0.04216662 -0.04815261  0.0394957  -0.01404974 -0.00364608  0.09160304\n",
            "  0.05165796  0.04462574 -0.07384126  0.04261011  0.07791669  0.06598622\n",
            "  0.1057889   0.05125806 -0.01614742 -0.00615996  0.08294511  0.01251815\n",
            " -0.03714981  0.01085306 -0.01328322 -0.0504429  -0.02157401  0.00952708\n",
            "  0.02950718  0.091218   -0.08202204  0.08427433  0.06619941 -0.0603001\n",
            " -0.02724924  0.0586716   0.03446574 -0.01435415 -0.02072423 -0.00294233\n",
            " -0.03397958 -0.01532629 -0.01169266  0.07165437  0.0386686  -0.04917542\n",
            "  0.02584689  0.06082812  0.05213424 -0.00038519 -0.06418698  0.04675699\n",
            "  0.04878818  0.08522116 -0.00655381  0.0490751  -0.01402193  0.02811201\n",
            " -0.0746011   0.08514383  0.02657601  0.01877743  0.11743415  0.02166902\n",
            "  0.15152155 -0.01699232  0.07183276  0.05115941 -0.04706223 -0.00850397\n",
            "  0.03458915  0.06377429  0.09164136 -0.05010843 -0.05573216  0.05007796\n",
            "  0.03321009 -0.03164304 -0.02811497  0.02656393 -0.07150734 -0.03867992\n",
            " -0.01189515  0.00767912  0.0753234   0.04527732  0.04097278  0.06148712\n",
            "  0.04289699  0.02258096  0.0675118  -0.02726303 -0.01709712 -0.00351795\n",
            "  0.04041767  0.01850721  0.06901029 -0.05679356 -0.04344379 -0.00711314\n",
            " -0.02004676  0.04653659 -0.03777293 -0.04421678  0.00913509 -0.0657548\n",
            "  0.01407253  0.05089712 -0.10406277 -0.01928236 -0.1355432   0.02877995\n",
            " -0.05278252  0.02016695  0.00261306 -0.00922521  0.00988076 -0.03517292\n",
            " -0.07257485 -0.02775101  0.06142663 -0.03887116 -0.04792688 -0.05933068\n",
            " -0.03212671 -0.00718403  0.00475253  0.02581315  0.00677497  0.03284954\n",
            " -0.00937904 -0.00299308  0.02524505  0.02257301  0.01669064  0.01550477\n",
            " -0.03843421  0.0192384   0.02195187 -0.05956763 -0.0014735  -0.02582246\n",
            "  0.01706225 -0.00437493  0.00892576  0.02099262  0.01382517  0.0271719\n",
            "  0.07364381 -0.01253449 -0.08373099  0.02731678 -0.03981555  0.00462771\n",
            " -0.02051537 -0.01233808  0.09598774  0.0414351   0.1423061  -0.08239342\n",
            "  0.07511931 -0.00504595 -0.04541733  0.06070369  0.05893687  0.03988843\n",
            "  0.01786886  0.03648331  0.03753839 -0.01008363  0.01741371 -0.04170849\n",
            "  0.0550492   0.01363357  0.0060408   0.06800457 -0.02672449  0.00732579\n",
            "  0.0939324   0.07014644 -0.00174568 -0.00384836 -0.03249849 -0.01289398\n",
            "  0.04767874  0.04693499 -0.07564781  0.02551229  0.02185111  0.0340694\n",
            "  0.04300012  0.00457303 -0.00439752 -0.07436907 -0.03044019 -0.09536605\n",
            "  0.05848373  0.01773322  0.03324027  0.01988043  0.01706287 -0.02197149\n",
            "  0.02939152  0.03639091 -0.00571249  0.08664902 -0.0386609   0.01423961\n",
            " -0.0124596   0.07426126 -0.02315525  0.09704097  0.04431284 -0.01560661\n",
            "  0.00656012  0.12334087 -0.03568402  0.02985649  0.02587489  0.02904386\n",
            " -0.00973366  0.02386793  0.00748295  0.07407155  0.01330972  0.04763379\n",
            "  0.05366801  0.08457668  0.03928425 -0.05181443  0.04788182  0.07709248\n",
            " -0.01172379  0.02970502 -0.00043991 -0.00620989  0.00878494 -0.00621177\n",
            "  0.00023147 -0.01241718  0.10861629 -0.01269052  0.03372663 -0.03284307\n",
            "  0.0238579  -0.00283238 -0.03128052 -0.03286495  0.02727329  0.05804717\n",
            " -0.02133219 -0.05236638  0.04747227  0.00185013  0.04524364 -0.04232267\n",
            "  0.02442057  0.0157615   0.08995111  0.05771054  0.02861718 -0.03559668\n",
            "  0.00678403  0.01808359  0.03709375  0.02800547  0.00728697  0.05135056\n",
            " -0.05175245  0.09771194 -0.00923032  0.02404552  0.0605599   0.03087374\n",
            " -0.00766468  0.05170628  0.05457668  0.03458627 -0.0090338   0.11389384\n",
            "  0.05708011  0.00235167  0.01571353 -0.03069654 -0.09382347 -0.01755263\n",
            "  0.01155968  0.01157283 -0.05555885 -0.01143215  0.02330771  0.03230364\n",
            "  0.16445163  0.05730947 -0.03239491  0.05842143 -0.0456834   0.05681127\n",
            " -0.08505525 -0.02843384 -0.00158534 -0.0193859  -0.06144567  0.04654796\n",
            " -0.03644407 -0.03863682  0.00831568 -0.00839029 -0.02604878 -0.03273244\n",
            "  0.07036489 -0.00474835 -0.0539573   0.02857297 -0.02779709  0.00204781\n",
            "  0.01316103  0.01304111  0.10104925 -0.05618409  0.04676189  0.02870407\n",
            "  0.02328723  0.02337837  0.00662436  0.07478151  0.02705667  0.06591668\n",
            " -0.00161757  0.05897271 -0.06413344 -0.03750644 -0.06564444  0.03784489\n",
            "  0.06948254 -0.0795084 ]\n",
            "Weight 3 - Shape: (784, 512)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [1. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "Weight 4 - Shape: ()\n",
            "0.039772596\n",
            "Weight 5 - Shape: ()\n",
            "3000\n",
            "Weight 6 - Shape: (512, 10)\n",
            "[[-0.         -0.         -0.28774634 ... -0.          0.\n",
            "   0.        ]\n",
            " [-0.27510467 -0.          0.         ... -0.          0.\n",
            "   0.        ]\n",
            " [-0.         -0.3585984   0.         ... -0.          0.\n",
            "   0.        ]\n",
            " ...\n",
            " [-0.3488775   0.          0.         ... -0.25522473 -0.23641942\n",
            "  -0.        ]\n",
            " [-0.         -0.25991586  0.         ... -0.          0.\n",
            "   0.        ]\n",
            " [-0.          0.          0.         ...  0.         -0.\n",
            "   0.        ]]\n",
            "Weight 7 - Shape: (10,)\n",
            "[-0.10533774 -0.0584163  -0.02285371 -0.05974628  0.01496729  0.03890281\n",
            " -0.01635682 -0.0391984   0.10775994 -0.03754989]\n",
            "Weight 8 - Shape: (512, 10)\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 1. 1. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Weight 9 - Shape: ()\n",
            "0.20487416\n",
            "Weight 10 - Shape: ()\n",
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weights for the original model:\")\n",
        "for i, weight in enumerate(initial_weights):\n",
        "    print(f\"Weight {i + 1} - Shape: {weight.shape}\")\n",
        "    print(weight)\n",
        "\n",
        "# Iterate through and print all weights for the pruned model\n",
        "print(\"\\nWeights for the pruned model:\")\n",
        "for i, weight in enumerate(pruned_weights):\n",
        "    print(f\"Weight {i + 1} - Shape: {weight.shape}\")\n",
        "    print(weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd4t6AuS4B3M",
        "outputId": "69f9c181-db8a-445d-d045-a037392f4aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights for the original model:\n",
            "Weight 1 - Shape: (784, 512)\n",
            "[[ 0.02700045  0.00013137  0.0456213  ...  0.04088297 -0.05537191\n",
            "   0.03707785]\n",
            " [-0.06099114  0.06337878 -0.05096041 ... -0.03281263  0.02436842\n",
            "   0.02593797]\n",
            " [-0.06537096 -0.04980753  0.04458294 ...  0.05752823 -0.02537625\n",
            "   0.03703913]\n",
            " ...\n",
            " [ 0.02991493 -0.04042678 -0.05210917 ...  0.03798266  0.02630352\n",
            "  -0.02415903]\n",
            " [ 0.00094448  0.05576134  0.03025601 ... -0.06366701 -0.03581608\n",
            "   0.02825262]\n",
            " [-0.007358    0.03549149  0.02898478 ...  0.02629033  0.06240831\n",
            "   0.01139142]]\n",
            "Weight 2 - Shape: (512,)\n",
            "[-3.35483328e-02  3.87791777e-03  5.43366112e-02  5.30741327e-02\n",
            "  7.16805980e-02  2.14986000e-02  4.84295376e-03 -3.65804248e-02\n",
            " -5.55107780e-02  6.53344542e-02  2.48677824e-02  1.81697998e-02\n",
            " -7.69754797e-02  6.27382696e-02 -7.53372442e-05  4.18999158e-02\n",
            " -3.59975323e-02  2.12241430e-05  2.11209734e-03  5.91290481e-02\n",
            "  6.11435100e-02  8.95328671e-02 -4.85626273e-02 -4.19506952e-02\n",
            "  6.56544641e-02 -1.31097697e-02 -8.25660536e-04 -7.92174879e-03\n",
            "  6.85921609e-02 -1.83727723e-02 -1.55268749e-03 -1.35291992e-02\n",
            "  2.49801874e-02  5.43493591e-02 -2.39697844e-02  1.92793962e-02\n",
            "  5.28803654e-02  1.65923759e-02 -5.20178564e-02 -1.95307881e-02\n",
            "  4.55425493e-02 -7.25719472e-03  1.47950305e-02  8.43468774e-03\n",
            " -9.59424768e-03  1.75603703e-02 -1.81266591e-02 -3.84222083e-02\n",
            " -4.27185781e-02  1.71754118e-02 -1.11299809e-02  5.83032779e-02\n",
            " -3.31147164e-02  1.12830233e-02 -2.30879197e-03 -1.96660403e-03\n",
            "  9.64934826e-02  8.57777745e-02  3.47353239e-03  3.82725559e-02\n",
            "  5.23659997e-02  1.36193344e-02  1.32230166e-02 -2.65875850e-02\n",
            " -2.14986445e-04 -2.78813783e-02  2.39197277e-02 -2.30443962e-02\n",
            "  6.44735023e-02  4.13981453e-02  1.58601347e-03 -1.04339272e-02\n",
            " -4.35028737e-03  2.87134945e-02 -2.64721084e-02 -6.82361936e-03\n",
            " -5.43796504e-03  4.02311124e-02 -1.86901838e-02 -4.62191366e-03\n",
            "  6.16221987e-02 -2.26502195e-02 -8.34725425e-03  7.80758187e-02\n",
            " -3.40831988e-02  8.64572451e-02  2.10474618e-02  8.85752961e-03\n",
            "  5.57938218e-03  1.46862655e-03  2.16632262e-02  3.83233652e-02\n",
            " -3.32028121e-02  5.99213876e-02 -3.20704691e-02 -1.50639834e-02\n",
            " -4.23129313e-02 -2.03461517e-02 -1.16163544e-01 -3.80846113e-02\n",
            " -8.71550292e-03  9.90952179e-02 -5.23148850e-02  1.59871243e-02\n",
            "  1.75108854e-02  2.00248659e-02  1.60941985e-02 -1.68688111e-02\n",
            " -4.51471657e-02  5.13938488e-04  3.68252620e-02  7.16309901e-03\n",
            " -1.17202951e-02  2.98683625e-02  6.52782544e-02  7.33328164e-02\n",
            "  2.90087759e-02 -1.34374835e-02 -3.25478762e-02 -2.51647290e-02\n",
            " -3.90233733e-02  1.02702891e-02  1.55313890e-02  5.21890186e-02\n",
            "  2.01576650e-02 -9.02918051e-04 -1.70105435e-02 -3.77368666e-02\n",
            " -4.95823985e-03  1.68708563e-02 -2.23905835e-02 -9.48352553e-03\n",
            " -1.72648560e-02 -1.47450287e-02  1.42629221e-02  4.17970903e-02\n",
            "  2.27829833e-02  2.64015198e-02  9.77456011e-03  2.55788676e-02\n",
            " -1.90958586e-02  5.71735129e-02  4.36410727e-03 -3.33072133e-02\n",
            "  1.43412827e-02 -1.34848543e-02  5.57339452e-02  2.98308041e-02\n",
            "  4.49019261e-02  2.00767051e-02 -2.04059407e-02  1.08779799e-02\n",
            "  1.27381803e-02  1.21889133e-02  2.86888387e-02 -3.06844409e-03\n",
            "  2.48098746e-03 -3.34262364e-02  1.11863926e-01  1.58989988e-02\n",
            " -1.80436030e-03 -5.55609688e-02  3.81455012e-02  8.50678887e-03\n",
            "  1.57084353e-02 -1.92862172e-02 -4.86998744e-02 -2.54739206e-02\n",
            "  7.53743201e-02 -1.22731766e-02 -8.12300388e-03  2.47715767e-02\n",
            "  1.47260446e-02  2.29968503e-02  1.00208230e-01 -2.51933224e-02\n",
            "  5.01428954e-02  7.79927447e-02  6.53249845e-02 -1.47192124e-02\n",
            "  8.40473399e-02 -4.11323868e-02 -2.41615693e-03 -1.96604840e-02\n",
            " -4.37630266e-02 -1.46459965e-02  8.47710390e-03  6.84763596e-04\n",
            "  1.17555298e-02  5.65655828e-02  1.55790523e-02 -7.19725341e-02\n",
            "  1.37061654e-02  5.59818298e-02  5.83946072e-02 -2.39665210e-02\n",
            " -5.21770753e-02  3.74279320e-02  2.66739801e-02 -1.11353621e-02\n",
            " -3.67925987e-02 -5.08893328e-03 -4.81791012e-02  4.05275300e-02\n",
            "  1.11072389e-02 -1.18419118e-02 -8.44793860e-03 -2.24743951e-02\n",
            " -2.23265830e-02 -1.83135439e-02  9.31415334e-02 -6.88507222e-03\n",
            " -1.51435258e-02 -1.34097487e-02  1.17887359e-03 -3.23931873e-02\n",
            " -2.62997695e-03 -4.38137678e-03  2.24056020e-02  2.78840475e-02\n",
            "  4.92648268e-03 -2.58047692e-02 -6.09512739e-02  3.34244147e-02\n",
            " -1.80976987e-02 -3.64823290e-03 -2.38068271e-02  4.41898070e-02\n",
            "  6.72658253e-03 -5.35335615e-02 -3.12191527e-02 -8.78266059e-03\n",
            "  8.65641050e-03  1.93883106e-02  4.75102626e-02  2.74435012e-03\n",
            " -1.32630458e-02 -1.83182694e-02 -1.69162191e-02 -3.75974923e-02\n",
            " -2.78288666e-02 -3.12584564e-02 -4.63423096e-02  6.36974350e-02\n",
            "  6.26831781e-03 -6.53247759e-02 -3.48793231e-02 -6.55482290e-03\n",
            "  5.47065809e-02  7.22331135e-03 -6.88900203e-02  7.19349161e-02\n",
            "  2.52192095e-02 -3.54372477e-03 -2.62053199e-02 -1.22528076e-02\n",
            " -5.93080837e-03  2.90391035e-02  5.01714163e-02  4.33464088e-02\n",
            "  4.53866553e-03  2.43728328e-02  4.53580031e-03 -6.20818138e-02\n",
            " -1.69752538e-02 -3.95575613e-02 -4.44353521e-02 -2.24061906e-02\n",
            "  1.83016974e-02  2.25326344e-02 -2.39224434e-02 -1.54428286e-02\n",
            " -1.45196682e-03 -1.64239202e-02 -1.57967415e-02  1.62632838e-02\n",
            " -5.39237540e-03 -1.45343421e-02 -1.73992515e-02  6.29134253e-02\n",
            "  3.09262425e-02 -1.80016514e-02 -3.67920920e-02 -2.63497829e-02\n",
            " -2.04784088e-02 -8.17980897e-03 -3.77371497e-02  2.61508077e-02\n",
            " -1.34811355e-02 -2.18474567e-02  4.72188108e-02 -2.11208984e-02\n",
            "  3.72718610e-02  2.22187135e-02  5.64417168e-02  5.70678210e-04\n",
            " -5.19032357e-03 -1.17435707e-02 -4.64998558e-02 -5.86056747e-02\n",
            " -4.58795540e-02 -2.16917768e-02  7.81783927e-03 -1.48134418e-02\n",
            "  1.28239200e-01 -3.63772735e-04 -4.78301533e-02  2.22250167e-02\n",
            " -2.68915743e-02  4.48861197e-02  3.03267036e-03  4.28113304e-02\n",
            " -3.34928855e-02  3.24879326e-02  3.65738682e-02  7.74309635e-02\n",
            " -3.69519927e-02  5.33147790e-02  4.00128365e-02 -1.72152221e-02\n",
            "  1.18871564e-02  3.04251760e-02  6.60131723e-02  4.54704687e-02\n",
            "  7.86078796e-02 -1.05031971e-02  3.54931578e-02  1.67010650e-02\n",
            "  7.53018185e-02  2.91125849e-03  6.77991733e-02 -9.04906262e-03\n",
            "  1.44076152e-02 -2.92402823e-02  3.27772647e-02  2.26189569e-02\n",
            "  2.90607605e-02 -4.85826135e-02  2.67415922e-02  5.33703789e-02\n",
            "  7.38857174e-03  2.35788096e-02 -2.97525376e-02 -2.79404391e-02\n",
            " -2.15878468e-02  2.89044306e-02 -1.62560027e-02 -2.14022733e-02\n",
            " -2.50093993e-02 -1.61256753e-02  3.66634165e-04 -5.54729104e-02\n",
            "  4.12546098e-02  3.47431451e-02  7.65670324e-03  4.58558686e-02\n",
            " -2.41505690e-02  3.88035253e-02  5.48364297e-02  7.70751666e-03\n",
            " -2.36238334e-02 -1.36475991e-02 -1.96602065e-02  5.01066679e-03\n",
            " -2.20587514e-02 -7.60404440e-03 -2.16394253e-02 -1.31051363e-02\n",
            "  5.74975833e-03 -6.69318736e-02 -4.68413904e-02 -4.85132784e-02\n",
            "  4.57841568e-02 -2.69962549e-02 -6.75794296e-03  1.35982046e-02\n",
            " -2.96526458e-02  1.20005626e-02  1.32195437e-02 -3.55976410e-02\n",
            "  3.33029814e-02  6.81417901e-03  2.79180128e-02  2.32231915e-02\n",
            " -1.56539846e-02 -7.04388618e-02  3.64881679e-02  1.12790451e-03\n",
            "  1.42957736e-02 -1.32114757e-02  3.77449729e-02 -1.72436107e-02\n",
            "  3.43802348e-02  3.47618498e-02 -1.38796270e-02 -2.64005363e-02\n",
            " -3.90478596e-02 -1.49482014e-02 -1.01669524e-02 -3.28068323e-02\n",
            "  7.28931557e-03 -8.44351426e-02  5.53335734e-02 -3.91188748e-02\n",
            "  8.40814970e-03 -2.63431501e-02  5.19646779e-02  1.96367446e-02\n",
            " -4.91266698e-02 -2.90214084e-02  3.39940302e-02 -2.56032795e-02\n",
            "  1.49451534e-03  1.63203273e-02 -3.50380503e-02 -4.79004271e-02\n",
            "  8.65498930e-02 -1.53601924e-02  2.78976541e-02 -4.02501971e-02\n",
            " -4.87761162e-02 -4.62067276e-02  2.15092115e-02 -1.81247294e-02\n",
            " -1.90104377e-02 -2.27562338e-03 -4.48766612e-02 -1.15025816e-02\n",
            " -1.95007697e-02  2.62480974e-02  4.11630943e-02  4.98565510e-02\n",
            " -3.48624960e-02 -1.48371300e-02  1.69256702e-02  9.85339005e-03\n",
            " -1.67651812e-03 -2.30381638e-02 -2.42055338e-02  5.56705445e-02\n",
            " -9.57092736e-03  4.95642163e-02 -2.21240930e-02 -2.26311348e-02\n",
            "  7.67877884e-03 -9.55877011e-04  1.61994230e-02 -6.73151538e-02\n",
            " -2.47376915e-02  1.79887842e-02  2.78656837e-03 -4.63304333e-02\n",
            "  8.07772353e-02 -3.02821444e-03  8.18950217e-03  3.39658372e-02\n",
            " -3.63429785e-02  7.01661333e-02  3.20792869e-02  5.15911244e-02\n",
            "  5.61053073e-03  1.31056998e-02 -3.04894820e-02  1.30063351e-02\n",
            " -2.88438555e-02 -1.93837527e-02  6.52732188e-03 -1.86429452e-02\n",
            " -1.01352381e-02 -7.53849074e-02  3.87549922e-02  3.50775868e-02\n",
            " -2.60215644e-02 -3.89688499e-02 -7.15595782e-02 -4.14756089e-02\n",
            " -3.31790000e-02  5.41093275e-02 -1.21412836e-02  5.81665989e-03\n",
            "  4.92292680e-02  1.03324883e-01  1.02165034e-02 -9.13796667e-03\n",
            "  5.77588659e-03 -1.49899423e-02  3.28805745e-02 -7.66853690e-02\n",
            "  7.55339190e-02  7.36310482e-02  8.90447423e-02 -1.17854979e-02\n",
            "  3.15418504e-02 -3.87572870e-03 -9.48964059e-03 -8.78846087e-03\n",
            "  4.69782352e-02  1.28847826e-03 -8.55518878e-03 -2.32907962e-02\n",
            " -1.56494100e-02  3.34057324e-02 -3.56068797e-02  5.52343321e-04\n",
            " -1.36763817e-02  8.16275424e-05  1.62735358e-02 -3.05161867e-02\n",
            " -3.23979370e-02  8.46687611e-03 -2.77848709e-02 -3.78375538e-02]\n",
            "Weight 3 - Shape: (512, 10)\n",
            "[[ 0.01677987 -0.10173981  0.07558804 ...  0.00323061 -0.18717349\n",
            "   0.06925303]\n",
            " [-0.1497143  -0.11322054  0.07259562 ...  0.02436622  0.07307814\n",
            "   0.05161115]\n",
            " [-0.20493819 -0.39456555 -0.1148647  ...  0.06760968 -0.22374679\n",
            "   0.02051339]\n",
            " ...\n",
            " [-0.01047959  0.01286967  0.15760444 ... -0.13214517 -0.40754607\n",
            "   0.13199618]\n",
            " [-0.07454791 -0.06485593  0.10446683 ...  0.10484982 -0.03847655\n",
            "  -0.44047585]\n",
            " [-0.01684497 -0.02183519  0.13460395 ... -0.0253097  -0.02760611\n",
            "   0.15255064]]\n",
            "Weight 4 - Shape: (10,)\n",
            "[-0.05702901 -0.0454346  -0.01806681 -0.02296994  0.00896663  0.03268226\n",
            " -0.04843405 -0.02638979  0.06304694  0.00389502]\n",
            "\n",
            "Weights for the pruned model:\n",
            "Weight 1 - Shape: (784, 512)\n",
            "[[ 0.  0.  0. ...  0. -0.  0.]\n",
            " [-0.  0. -0. ... -0.  0.  0.]\n",
            " [-0. -0.  0. ...  0. -0.  0.]\n",
            " ...\n",
            " [ 0. -0. -0. ...  0.  0. -0.]\n",
            " [ 0.  0.  0. ... -0. -0.  0.]\n",
            " [-0.  0.  0. ...  0.  0.  0.]]\n",
            "Weight 2 - Shape: (512,)\n",
            "[-2.99059357e-02  1.51017560e-02  1.07773513e-01  2.64636856e-02\n",
            "  7.49693736e-02 -1.51054654e-02  1.36306765e-03 -5.99684455e-02\n",
            " -6.56655356e-02  9.33975503e-02  8.55769664e-02 -2.37537809e-02\n",
            " -1.04933284e-01  7.56741762e-02  3.28853130e-02  3.87420170e-02\n",
            " -8.18773806e-02  1.12602254e-03 -5.66608720e-02  5.17607369e-02\n",
            "  6.04367033e-02  6.62041530e-02 -7.20833912e-02 -3.33470218e-02\n",
            "  8.34592953e-02  6.16539791e-02  2.93883272e-02 -3.39357145e-02\n",
            "  1.05173536e-01 -2.94693615e-02  1.45701244e-02 -1.15089212e-02\n",
            "  6.91250637e-02  9.07597393e-02  1.17459008e-02  4.63470742e-02\n",
            "  5.33571914e-02  2.22384911e-02 -6.10589013e-02  2.54176073e-02\n",
            "  5.67285605e-02  8.68953206e-03  5.19445464e-02 -1.47281727e-02\n",
            " -3.98652107e-02  1.89907178e-02  4.43025539e-03 -4.46429513e-02\n",
            "  7.36301625e-03  7.39024505e-02 -5.22521324e-02  4.92470972e-02\n",
            " -2.58533917e-02  5.16025499e-02 -3.43494117e-02 -5.76194264e-02\n",
            "  1.14564076e-01  9.89297256e-02  6.41402975e-02  9.06353146e-02\n",
            "  3.49805914e-02  9.06630885e-03  5.02105206e-02 -7.48035610e-02\n",
            "  2.32350081e-02  1.85831599e-02 -3.55578288e-02 -6.12374209e-02\n",
            "  9.63592380e-02  1.03826262e-02 -1.92648787e-02  6.43419381e-03\n",
            "  1.45294508e-02  2.83005983e-02  1.11285551e-02 -6.75841980e-03\n",
            " -2.10484546e-02  3.79113518e-02 -1.12493671e-02 -2.00135931e-02\n",
            "  5.63481487e-02 -4.44919690e-02  2.53209635e-03  9.05088112e-02\n",
            " -4.57306132e-02  7.73565397e-02 -1.13549158e-02 -3.69612798e-02\n",
            "  8.45219288e-03  2.79895831e-02 -5.92233101e-03  1.01083703e-01\n",
            " -6.75426200e-02  8.87497440e-02 -1.96779948e-02 -1.15925074e-02\n",
            " -3.33409794e-02 -3.03682704e-02 -1.66879192e-01 -4.29013036e-02\n",
            " -5.21802856e-03  8.26974660e-02 -1.40140846e-01  1.34668946e-02\n",
            "  4.79235724e-02  2.08273157e-02  3.79829407e-02 -7.76052922e-02\n",
            " -3.88206318e-02  2.01256201e-02 -2.94233067e-03  3.00036334e-02\n",
            "  2.33774222e-02 -1.77028333e-03  8.08687061e-02  8.56853426e-02\n",
            "  7.72349015e-02 -8.98979791e-03 -7.93938860e-02 -3.81712690e-02\n",
            " -4.96567748e-02  1.74095258e-02  2.73957904e-02  4.83255647e-02\n",
            "  4.04522270e-02 -3.11113410e-02  1.34210428e-02 -5.19193709e-02\n",
            " -5.22790477e-02  4.02805470e-02 -2.24606842e-02 -2.92008985e-02\n",
            "  3.57980654e-02 -6.39136583e-02  1.67266056e-02  3.43020214e-03\n",
            "  2.76854858e-02  3.32945697e-02  1.38040176e-02  2.12675799e-02\n",
            " -1.86799951e-02  4.61463481e-02 -3.50112058e-02 -5.69062531e-02\n",
            " -6.51525683e-04 -1.18511878e-02  2.22781058e-02  4.68086898e-02\n",
            "  6.54577613e-02  6.06257506e-02 -7.41012320e-02  3.41246091e-02\n",
            "  8.95683244e-02  4.82286438e-02  6.18522055e-02  1.43025462e-02\n",
            "  9.39986948e-03 -6.92673549e-02  1.36893436e-01  5.98622411e-02\n",
            "  1.05162766e-02 -4.43774462e-02  1.24239810e-02  3.29052694e-02\n",
            "  3.71842422e-02 -1.05013279e-02 -3.25992033e-02 -4.63747121e-02\n",
            "  8.41874257e-02 -2.08611451e-02  6.33934289e-02  4.26859371e-02\n",
            "  1.25819407e-02 -3.84889618e-02  1.32553384e-01 -7.17884153e-02\n",
            "  7.93716088e-02  1.07542709e-01  4.81069237e-02  1.66984778e-02\n",
            "  9.31096599e-02 -6.10279664e-02 -3.83912846e-02 -2.11699624e-02\n",
            " -7.24567398e-02 -3.29447761e-02 -6.73921034e-02  5.06376028e-02\n",
            "  5.47754318e-02  8.66800994e-02 -2.87729222e-03 -6.84986860e-02\n",
            "  3.49078961e-02  6.03051297e-02  3.24287713e-02 -9.41723213e-02\n",
            " -2.54528839e-02  1.40536949e-02  2.10874528e-02 -1.43999420e-02\n",
            " -2.50168331e-02  4.55626361e-02 -5.98195195e-02  1.41488574e-02\n",
            "  4.17640321e-02 -2.07997374e-02 -2.97790300e-02 -3.94229926e-02\n",
            " -3.58571075e-02 -9.47474502e-03  1.65373519e-01 -2.03831606e-02\n",
            " -1.67466961e-02 -4.49594520e-02  5.83488159e-02 -6.17644526e-02\n",
            " -8.92056338e-03 -7.35427216e-02 -1.56568276e-04  2.72995420e-02\n",
            " -1.60533329e-03  6.35396689e-03 -1.24731615e-01  2.57917531e-02\n",
            " -6.58452958e-02  8.84540230e-02 -1.63929760e-02  4.10159230e-02\n",
            " -2.44332943e-02 -6.98322579e-02 -2.57361084e-02 -4.56765890e-02\n",
            "  3.66753526e-02 -1.76703054e-02  7.94807300e-02  1.44588081e-02\n",
            "  3.51498239e-02 -4.21026386e-02 -2.01650690e-02 -4.95860092e-02\n",
            " -5.85475676e-02 -8.93271938e-02 -3.66446041e-02  1.42745376e-01\n",
            "  2.91916989e-02 -5.17472848e-02 -6.46742657e-02  4.69778031e-02\n",
            "  4.68369536e-02  4.78725024e-02 -1.13744117e-01  1.91506986e-02\n",
            " -2.07394864e-02 -2.53883991e-02 -1.31034320e-02 -3.30590531e-02\n",
            "  2.47619655e-02  7.09361956e-02  9.29262415e-02  4.16427739e-02\n",
            "  3.55602987e-03  1.40299825e-02 -1.05939144e-02 -3.98697741e-02\n",
            " -9.41346213e-03 -4.23580781e-02 -3.28624174e-02 -6.58769682e-02\n",
            "  5.02831861e-02  7.96136558e-02 -5.40434867e-02 -2.23417263e-02\n",
            " -1.54619785e-02 -2.81304121e-02 -5.97083569e-03  1.43493647e-02\n",
            " -3.69810201e-02  6.47360738e-03 -4.42527309e-02  3.53625789e-02\n",
            "  3.29997055e-02  2.53061894e-02 -4.13824059e-02 -6.24034181e-02\n",
            " -6.43341541e-02 -2.96106003e-02 -3.07750236e-02  6.03801347e-02\n",
            " -1.36255845e-02 -9.79131162e-02  3.66261080e-02  5.51272333e-02\n",
            "  4.96456325e-02  4.73736972e-02  1.08495831e-01 -8.21788423e-03\n",
            "  3.70291919e-02 -4.33289520e-02 -9.27045420e-02 -6.28094971e-02\n",
            " -1.42629057e-01 -2.43213139e-02  1.22439656e-02  1.22846221e-03\n",
            "  1.79167047e-01  1.04963582e-03 -5.22975624e-02  2.18573287e-02\n",
            " -7.22234175e-02  2.30018850e-02  2.35606302e-02  5.64769357e-02\n",
            " -3.29470187e-02  6.75973147e-02  1.41619265e-01  1.15624018e-01\n",
            " -2.69381143e-02  5.56412600e-02  6.28970712e-02 -2.00593397e-02\n",
            " -5.03453938e-03  6.51579797e-02  7.33521357e-02  5.72644621e-02\n",
            "  6.04258180e-02  8.32102448e-02  6.53963722e-03 -1.70338657e-02\n",
            "  9.58280712e-02  7.49131888e-02  8.16426054e-02 -2.31599230e-02\n",
            " -2.21762457e-03 -2.74878256e-02  2.73310915e-02  3.04870009e-02\n",
            "  8.03433508e-02 -6.93180710e-02  2.86483020e-02  7.27171451e-02\n",
            "  4.47362028e-02  3.60449776e-02 -4.64986004e-02 -4.12836811e-03\n",
            " -2.74272058e-02  1.04893018e-02 -2.00812495e-03 -1.14266481e-02\n",
            " -4.89116237e-02 -1.48219205e-02 -9.82531719e-03 -8.50930214e-02\n",
            "  2.76680626e-02  2.84981146e-03  1.12827085e-02  1.81575008e-02\n",
            " -3.55448164e-02  3.06260362e-02  8.23215097e-02  5.34754666e-03\n",
            "  4.09082398e-02 -2.84887850e-02  1.63017381e-02 -5.91815077e-02\n",
            " -2.58303266e-02 -1.88520513e-02 -2.19833944e-02  3.77680641e-03\n",
            "  4.78209667e-02 -6.71421438e-02 -5.18579036e-02 -3.50833982e-02\n",
            "  7.05341846e-02  7.29446905e-03 -3.69585417e-02  4.51602228e-02\n",
            " -2.40535811e-02  9.76440776e-03  2.51811948e-02 -5.95073439e-02\n",
            "  9.25242808e-03  2.31618192e-02  3.71966325e-02  7.89182037e-02\n",
            " -7.52098509e-04  2.25005252e-03  4.85347137e-02  2.34884918e-02\n",
            " -8.56705476e-03 -5.63880950e-02  7.54322261e-02 -1.66752245e-02\n",
            "  9.85422805e-02  7.19681978e-02 -4.49355915e-02 -2.41550300e-02\n",
            " -8.13234150e-02 -1.48684904e-02 -7.62790665e-02 -2.27352008e-02\n",
            "  7.73490146e-02 -8.39412436e-02  8.55382830e-02 -3.10657788e-02\n",
            " -1.87967550e-02 -7.90485740e-03  9.11639631e-02 -3.68042383e-03\n",
            " -2.56629344e-02  2.01114733e-02  4.15135995e-02 -6.19046316e-02\n",
            " -7.26494491e-02 -2.93720458e-02 -3.30628641e-02 -1.08413562e-01\n",
            "  9.84339565e-02 -6.18982781e-03 -1.01967752e-02 -3.99007797e-02\n",
            " -5.85565642e-02 -4.26855534e-02  2.44915579e-02  2.46077478e-02\n",
            "  2.95531433e-02  3.79583910e-02 -3.40132192e-02 -3.15776914e-02\n",
            " -9.48040374e-03  5.59399389e-02  5.85616492e-02  3.12916376e-02\n",
            " -2.63955984e-02 -1.48343481e-02  2.34274138e-02 -3.31158843e-03\n",
            "  3.79701033e-02 -2.85662953e-02 -4.08382826e-02  6.37224168e-02\n",
            "  6.45403983e-03  7.66278133e-02 -3.00771929e-02 -1.90523695e-02\n",
            "  7.16286078e-02  1.81343611e-02 -7.48972967e-02 -1.17581181e-01\n",
            " -1.49785979e-02 -1.20406365e-02  2.62795612e-02 -6.66556880e-02\n",
            "  9.91711989e-02 -3.99227887e-02  2.89787110e-02  3.25919613e-02\n",
            " -9.74723399e-02  5.30135781e-02  2.43521202e-02 -6.89623831e-03\n",
            "  4.87240888e-02 -5.21929078e-02 -4.12349217e-02 -2.26063491e-03\n",
            " -5.70617914e-02 -4.28094715e-02 -1.34136900e-02 -5.54132217e-04\n",
            " -4.84185517e-02 -1.12376116e-01  2.50263866e-02  7.80770034e-02\n",
            " -1.85601208e-02 -5.76941036e-02 -6.14147373e-02 -1.04297310e-01\n",
            " -1.97536349e-02  6.76196069e-02  1.36562604e-02  1.94372740e-02\n",
            " -6.99916680e-04  1.45627514e-01 -2.26853043e-02  3.55569758e-02\n",
            "  1.21720349e-02 -3.20357084e-02  1.98070947e-02 -9.28317830e-02\n",
            "  5.17527573e-02  1.08988561e-01  1.23469584e-01  4.90045291e-04\n",
            "  3.77661660e-02  5.00236172e-03 -1.99084124e-03 -7.68379420e-02\n",
            "  8.63279998e-02 -3.00143640e-02 -1.00144222e-02 -3.08128819e-02\n",
            " -2.13850290e-02  7.20339129e-03 -1.56064909e-02  1.28894979e-02\n",
            " -1.18108355e-02  2.90414020e-02  5.29462937e-03  2.24394947e-02\n",
            " -8.02181102e-03 -5.63366041e-02 -8.07485878e-02 -3.33883688e-02]\n",
            "Weight 3 - Shape: (784, 512)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Weight 4 - Shape: ()\n",
            "0.0564214\n",
            "Weight 5 - Shape: ()\n",
            "3000\n",
            "Weight 6 - Shape: (512, 10)\n",
            "[[-0.         -0.          0.         ...  0.          0.\n",
            "  -0.        ]\n",
            " [ 0.         -0.         -0.         ...  0.          0.\n",
            "  -0.        ]\n",
            " [-0.         -0.5874963   0.         ... -0.          0.\n",
            "  -0.        ]\n",
            " ...\n",
            " [-0.         -0.          0.         ... -0.         -0.62047654\n",
            "  -0.        ]\n",
            " [-0.         -0.          0.         ...  0.          0.\n",
            "  -0.55697376]\n",
            " [-0.         -0.          0.         ...  0.          0.\n",
            "  -0.        ]]\n",
            "Weight 7 - Shape: (10,)\n",
            "[-0.1372097  -0.16987164 -0.03818079  0.02166918 -0.00127189  0.02991287\n",
            " -0.0953978  -0.1332855   0.13156582  0.05097849]\n",
            "Weight 8 - Shape: (512, 10)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Weight 9 - Shape: ()\n",
            "0.3317259\n",
            "Weight 10 - Shape: ()\n",
            "3000\n"
          ]
        }
      ]
    }
  ]
}